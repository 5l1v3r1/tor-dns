\appendix

We provide details on how to replicate our results.  Each
subsection discusses the replication of a specific experiment, providing both
code and data necessary to replicate.

\subsection{Replicating AS exposure of DNS}
Here is how you can replicate the results of Subsection~\ref{sec:as-exposure}.
First, obtain the Python 2 tool ddptr that we have developed for this
measurement task:

\begin{lstlisting}
git clone https://github.com/NullHypothesis/ddptr.git
\end{lstlisting}

Next, you need two files to continue; \first a list of websites such as the
AlexaTop 1,000~\cite{alexatop1k}, which you should save as top-1k.csv; \second a
file ipasn.dat, which enables looking up AS numbers for given IP addresses.  The
library pyasn documents how you can generate this file~\cite{pyasn}.  After
having fetched top-1k.csv, ipasn.dat and ddptr.py, you are ready to run it as
follows:

\begin{lstlisting}
sudo ./ddptr.py --fqdn-file top-1k.csv ipasn.dat 2>&1 | tee top-1k-ddptr.log
\end{lstlisting}

The resulting log files contains plenty of information, but only the lines
``Exposure is \ldots'' are necessary to create Figure~\ref{fig:exposure}.  You
can extract all exposure values from the log files by running:

\begin{lstlisting}
echo exposure > exposures.csv
grep Exposure top-1k-ddptr.log | awk '{print $NF}' >> exposures.csv
\end{lstlisting}

The file exposures.csv then contains all exposure values, one per line,
including a header line.  It is easy to take the file and plot it with a tool of
your choice.

\subsection{Replicating DNS resolver mapping}
Here is how you can replicate the results of
Subsection~\ref{sec:mapping-resolvers}.  First, you need to set up an
authoritative DNS server for a domain that is under your control.  We set up
a bind9 instance that was responsible for the zone *.tor.nymity.ch.  We
configured bind9 to return the same IP address for any request under
tor.nymity.ch.

Next, you need the Python 2 exitmap scanner~\cite{exitmap}:

\begin{lstlisting}
git clone https://github.com/NullHypothesis/exitmap.git
\end{lstlisting}

We developed a special module for exitmap that is part of the following git
repository.  You can clone it, and then copy the module to exitmap's modules
directory as follows:

\begin{lstlisting}
git clone https://github.com/NullHypothesis/tor-dns-tools.git
cp tor-dns-tools/exit-resolvers/dnsenum.py /path/to/exitmap/src/modules/
\end{lstlisting}

You are now ready to start the experiment.  On the machine running bind9, you
have to run tcpdump to capture all DNS requests going to bind9:

\begin{lstlisting}
tcpdump -n "udp and port 53" -w dns-requests.pcap
\end{lstlisting}

Bind9 is now ready to serve DNS requests and tcpdump is capturing them to a
file.  You can now run exitmap to generate the data:

\begin{lstlisting}

\end{lstlisting}

We set up a cronjob to run exitmap automatically every six hours.
First, edit your crontab:
\begin{lstlisting}
crontab -u "$USER" -e
\end{lstlisting}
Then, add the following line to the crontab file:
\begin{lstlisting}
0 */6 * * * /path/to/exitmap -f /path/to/exitmaprc dnsenum
\end{lstlisting}

The file exitmaprc had the following content.  The key \texttt{first\_hop} is
not necessary, but it makes scanning more reliable.  We set it to the
fingerprint of a Tor relay under our control.
\begin{lstlisting}
[Defaults]
first_hop = 9B94CD0B7B8057EAF21BA7F023B7A1C8CA9CE645
build_delay = 0.5
analysis_dir = /path/to/analysis_directory/
tor_dir = /path/to/tor_directory/
\end{lstlisting}

Having set up cron, exitmap will now run periodically, and the data you need
will be captured in the pcap file that is created on the machine running bind9.
Once you are ready to analyze the data, the README file of the following GitHub
repository discusses how you can turn the pcap file into visualizations:
\url{https://github.com/NullHypothesis/tor-dns-tools/tree/master/exit-resolvers}.

\subsection{Replicating number of DNS requests on exit relays}
Because of the ethical issues of recording data on exit relays, we developed a
patch for tshark that allows us to reduce the granularity of timestamps.  That
way, we are able to record the number of DNS requests in a given time period
without payload or further information.

\begin{lstlisting}
sudo ./tshark -n -f 'udp port 53' -T fields -e frame.time_epoch -Y 'dns.qry.type == 1 and dns.flags.response == 0'
\end{lstlisting}

\begin{lstlisting}
diff -Naur wireshark-1.12.1.orig/epan/frame_data.c wireshark-1.12.1/epan/frame_data.c
--- wireshark-1.12.1.orig/epan/frame_data.c     2014-09-16 18:09:03.000000000 +0200
+++ wireshark-1.12.1/epan/frame_data.c  2016-07-21 19:31:56.392000000 +0200
@@ -310,8 +310,8 @@
   fdata->flags.has_phdr_comment = (phdr->opt_comment != NULL);
   fdata->flags.has_user_comment = 0;
   fdata->color_filter = NULL;
-  fdata->abs_ts.secs = phdr->ts.secs;
-  fdata->abs_ts.nsecs = phdr->ts.nsecs;
+  fdata->abs_ts.secs = phdr->ts.secs - (phdr->ts.secs % 3600);
+  fdata->abs_ts.nsecs = 0;
   fdata->shift_offset.secs = 0;
   fdata->shift_offset.nsecs = 0;
   fdata->frame_ref_num = 0;
\end{lstlisting}

\begin{lstlisting}
patch -p0 < tshark-binned-timestamps.patch
\end{lstlisting}

The output of the command is coarse timestamps, one per line, of when tshark
captured a DNS request.

\subsection{Replicating DNS requests stats}
This is how you replicate the DNS-related statistics from
Section~\ref{sec:dns2site}.  First download and extract the Alexa top one
million websites dataset with extracted DNS requests:

\begin{lstlisting}
wget FIXME/alexa1mx5-extracted.tar.gz
tar -zxf alexa1mx5-extracted.tar.gz
\end{lstlisting}

Get the Alexa file we used when gathering the data~\cite{alexatop1k} and
the CloudFlare IPv4
addresses\footnote{\url{https://www.cloudflare.com/ips-v4}} at the time of
gathering:

\begin{lstlisting}
wget FIXME/top-1m.csv
wget FIXME/ips-v4
\end{lstlisting}

Get and install our dnsstats tool using Go\footnote{\url{https://golang.org/}}:

\begin{lstlisting}
go get github.com/pylls/dnsstats
\end{lstlisting}

Finally, run dnsstats on the downloaded data:

\begin{lstlisting}
dnsstats alexa1mx5-extracted/
\end{lstlisting}

This produces a large number of statistics, including those used in
 Section~\ref{sec:dns2site}.

\subsection{Replicating DNS to website classification}
This is how you replicate the DNS to website classification from
Section~\ref{sec:dns2site}.
First download and extract the Alexa top one
million websites dataset with extracted DNS requests:

\begin{lstlisting}
wget FIXME/alexa1mx5-extracted.tar.gz
tar -zxf alexa1mx5-extracted.tar.gz
\end{lstlisting}

Get and install our dns2site tool using Go:

\begin{lstlisting}
go get github.com/pylls/dns2site
\end{lstlisting}

For the closed world metrics, run:

\begin{lstlisting}
dns2site -sites 1000000 -instances 5 -open 0
\end{lstlisting}

For the open world metrics, run:

\begin{lstlisting}
dns2site -sites 500000 -instances 5
\end{lstlisting}

Without the \texttt{-open} parameter, the dns2site tool determines a reasonable
open world size based on our conservative power-law distribution,
which should be around 433,000.

\subsection{Replicating \name attacks}
This is how you replicate the \name results figures from
Section~\ref{sec:analysis}.
First download and extract the traffic traces from our
1,000x100+100,000 WF dataset:

\begin{lstlisting}
wget FIXME/alexa1kx100+100k-extracted.tar.gz
tar -zxf alexa1kx100+100k-extracted.tar.gz
\end{lstlisting}

Get and install our wfdns tool using Go:

\begin{lstlisting}
go get github.com/pylls/wfdns
\end{lstlisting}

To generate data for Figure~\ref{fig:wfdns:torpct}, run:

\begin{lstlisting}
wfdns -sites 1000 -instances 100 -open 100000 -pmin 0 -pmax 100 -pstep 5 -alexa 10000
\end{lstlisting}

The result is written to stdout and three files: one CSV file for precision,
one CSV file for recall, and a log of all output. All filenames capture relevant
parameters and are only created upon experiment completion.

To generate data for Figure~\ref{fig:wfdns:alexa}, run as a shellscript:

\begin{lstlisting}
for i in 1 10 100 1000 10000 100000 1000000 10000000 100000000
do
  wfdns -sites 1000 -instances 100 -open 100000 -pmin 100 -alexa $i
done
\end{lstlisting}

Manual assembly of the CSV files needed. For
Figures~\ref{fig:wfdns:var:rounds},~\ref{fig:wfdns:var:window},~\ref{fig:wfdns:var:scale},
and~\ref{fig:wfdns:var:dist}, run
as a shellscript:

\begin{lstlisting}
# rounds
for i in 0 300 600 900 1200 1500 1800 2100 2400 2700 3000
do
  wfdns -sites 1000 -instances 100 -open 100000 -pmin 33 -pmax 33 -alexa 10000 -r $i
done
# window size
for i in 90 180 360 540 720 900 1080 1260 1440 1620 1800
do
  for j in 10000 100000
  do
  wfdns -sites 1000 -instances 100 -open 100000 -pmin 33 -pmax 33 -window $i -alexa $j
  done
done
# Tor network scale
for i in 1.0 2.0 3.0 4.0 5.0 6.0 7.0 8.0 9.0 10.0
do
  for j in 10000 100000
  do
  wfdns -sites 1000 -instances 100 -open 100000 -pmin 33 -pmax 33 -scaletor $i -alexa $j
  done
done
# different distributions
for i in conpl realpl conuni realuni
do
  for j in 0 10 100 1000 10000 100000 1000000 10000000 100000000
  do
    wfdns -sites 1000 -instances 100 -open 100000 -pmin 33 -pmax 33 -simdist $i -alexa $j
  done
done
\end{lstlisting}

Manual assembly of the CSV files needed.
Note that generating the figures takes \emph{days} on modern
hardware: we spent well over a CPU core year in total on the figures.

\subsection{Replicating the DNS Alexa top 1,000,000 dataset}
This is how you replicate the steps we used to gather the Alexa top 1,000,000
dataset used in Section~\ref{sec:dns2site}.
First, get and install three tools using Go:

\begin{lstlisting}
go get github.com/pylls/tordns/cmd/{server,tbbdnsw,extractdns}
\end{lstlisting}

We use a worker-server model, where a server instructs workers to browse to a
site and return the observed DNS requests. Download an Alexa file with top
sites~\cite{alexatop1k} and run the server:

\begin{lstlisting}
server -f data -s 5 -t 30 top-1m.csv
\end{lstlisting}
The server will instruct workers to collect in total
five samples of the sites in top-1m.csv, using 30 seconds per site visit,
and store the results in the data folder. By default, the server listens on
port 55555 on all interfaces.

Download a fresh copy of TBB from \url{https://torproject.org} and extract it.
Open Browser/TorBrowser/Data/Browser/profile.default/preferences/
and put the
following \emph{at the bottom} of \texttt{extension-overrides.js}:

\begin{lstlisting}
user_pref("app.update.enabled", false);
user_pref("extensions.torlauncher.prompt_at_startup", false);
user_pref("extensions.torlauncher.start_tor", false);
user_pref("datareporting.healthreport.nextDataSubmissionTime", "1559373924100");
user_pref("datareporting.policy.firstRunTime", "1559287524100");
user_pref("extensions.torbutton.lastUpdateCheck", "1559287542.7");
user_pref("extensions.torbutton.show_slider_notification", false);
user_pref("extensions.torbutton.updateNeeded", false);
user_pref("extensions.torbutton.versioncheck_url", "");
user_pref("extensions.torbutton.versioncheck_enabled", false);
user_pref("network.proxy.proxy_over_tls", false);
user_pref("network.proxy.socks", "");
user_pref("network.proxy.socks_port", 0);
user_pref("network.proxy.socks_remote_dns", false);
\end{lstlisting}

Download the latest release of dumb-init from
\url{https://github.com/Yelp/dumb-init/releases}. We need a minimal init system
to clean up the many processes we will be creating in Docker.
Copy the following into a
new file named \texttt{Dockerfile}\footnote{Based on
\url{https://github.com/jfrazelle/dockerfiles/tree/master/tor-browser}.}:

\begin{lstlisting}
FROM debian:jessie
MAINTAINER Tobias Pulls <tobias.pulls@kau.se>

RUN apt-get update && apt-get install -y \
	xvfb \
	libpcap-dev \
	libasound2 \
	libdbus-glib-1-2 \
	libgtk2.0-0 \
	libxrender1 \
	libxt6 \
	xz-utils \
  xauth \
  psmisc \
	--no-install-recommends

COPY dumb-init*_amd64.deb /
RUN dpkg -i dumb-init*.deb
RUN rm dumb-init*.deb && apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

ENV HOME /home/user
ENV LANG C.UTF-8

# create user (start-tor-browser.sh prevents us from running as root)
RUN useradd --create-home --home-dir $HOME user

COPY tbbdnsw $HOME/
COPY tor-browser_en-US $HOME/tor-browser_en-US

RUN chown -R user:user $HOME \
	&& chmod +x $HOME/tbbdnsw \
  && setcap 'CAP_NET_RAW+eip CAP_NET_ADMIN+eip' $HOME/tbbdnsw

WORKDIR $HOME
USER user
ENTRYPOINT ["dumb-init", "--"]
\end{lstlisting}

Build the docker container and start a worker:

\begin{lstlisting}
docker build -t pulls/worker  .
docker run --privileged -d pulls/worker ./tbbdnsw <IP:port>
\end{lstlisting}
The worker will repeatedly try to connect to the server at <IP:port>. We
successfully ran 120 workers each 1U blades
with Intel(R) Xeon(R) CPU E5-2650 0 @ 2.00GHz with 62GB RAM. The server was
hosted on a laptop with SSD storage.

Finally, to extract the DNS data from the resulting pcaps use the
extractdns tool:

\begin{lstlisting}
extractdns -o results/ data/
\end{lstlisting}
Where data is the folder the server stored the data in and results is the folder
to store the extracted data in.

\subsection{Replicating the WF dataset}
To replicate our WF dataset used in Section~\ref{sec:analysis}, get and
install the following four tools using Go:
% server
\begin{lstlisting}
go get github.com/pylls/tordns/cmd/{server,tbbw,torlogext,fext}
\end{lstlisting}

Download an Alexa file with top sites~\cite{alexatop1k} and run:

\begin{lstlisting}
server -f data -s 5 -t 60 -o .torlog top-1m.csv
\end{lstlisting}
The server will instruct workers to collect in total
five samples of the sites in top-1m.csv, using 60 seconds per site visit,
and store the results in the data folder with the suffix \texttt{.torlog}.
By default, the server listens on port 55555 on all interfaces.

% configure Tor
Download a fresh copy of TBB from \url{https://torproject.org} and extract it.
Open Browser/TorBrowser/Data/Browser/profile.default/preferences/
and put the
following \emph{at the bottom} of \texttt{extension-overrides.js}:

\begin{lstlisting}
user_pref("app.update.enabled", false);
user_pref("extensions.torlauncher.prompt_at_startup", false);
user_pref("datareporting.healthreport.nextDataSubmissionTime", "1759373924100");
user_pref("datareporting.policy.firstRunTime", "1759287524100");
user_pref("extensions.torbutton.lastUpdateCheck", "1759287542.7");
user_pref("extensions.torbutton.show_slider_notification", false);
user_pref("extensions.torbutton.updateNeeded", false);
user_pref("extensions.torbutton.versioncheck_url", "");
user_pref("extensions.torbutton.versioncheck_enabled", false);
\end{lstlisting}

Open Browser/TorBrowser/Data/Tor/torrc and add:

\begin{lstlisting}
LogTimeGranularity 1
UseEntryGuards 0
\end{lstlisting}

% build custom tor
Next we need to build a custom tor for TBB that logs all incoming and outgoing
cells using Tor's logging framework. First, get the tor source code:

\begin{lstlisting}
git clone https://git.torproject.org/tor.git
\end{lstlisting}
Follow the instructions in the INSTALL file. Once you can build tor,
apply the below patch to src/or/relay.c and run make:
% clients
\begin{lstlisting}
diff -Naur tor/src/or/relay.c relay.c
--- tor/src/or/relay.c	2016-08-02 18:04:05.796809070 +0200
+++ relay.c	2016-08-02 18:03:50.036572253 +0200
@@ -585,6 +585,10 @@
     return -1;
   }

+  log_notice(LD_GENERAL, "OUTGOING CIRC %u STREAM %d COMMAND %s(%d) length %zu",
+             circ->n_circ_id, stream_id, relay_command_to_string(relay_command),
+             relay_command, payload_len);
+
   memset(&rh, 0, sizeof(rh));
   rh.command = relay_command;
   rh.stream_id = stream_id;
@@ -1453,6 +1457,9 @@
         ;
     }
   }
+  log_notice(LD_GENERAL, "INCOMING CIRC %u STREAM %d COMMAND %s(%d) length %d",
+             circ->n_circ_id, rh.stream_id,
+             relay_command_to_string(rh.command), rh.command, rh.length);

   /* either conn is NULL, in which case we've got a control cell, or else
    * conn points to the recognized stream. */
\end{lstlisting}
Copy src/or/tor to Browser/TorBrowser/tor.

Download the latest release of dumb-init from
\url{https://github.com/Yelp/dumb-init/releases}.
Copy the following into a
new file named \texttt{Dockerfile}:

\begin{lstlisting}
FROM debian:jessie
MAINTAINER Tobias Pulls <tobias.pulls@kau.se>

RUN apt-get update && apt-get install -y \
	xvfb \
	libpcap-dev \
	libasound2 \
	libdbus-glib-1-2 \
	libgtk2.0-0 \
	libxrender1 \
	libxt6 \
	xz-utils \
  xauth \
  psmisc \
	--no-install-recommends

COPY dumb-init*_amd64.deb /
RUN dpkg -i dumb-init*.deb
RUN rm dumb-init*.deb && apt-get clean && rm -rf /var/lib/apt/lists/* /tmp/* /var/tmp/*

ENV HOME /home/user
ENV LANG C.UTF-8

# create user (start-tor-browser.sh prevents us from running as root)
RUN useradd --create-home --home-dir $HOME user

COPY tbbw $HOME/
COPY tor-browser_en-US $HOME/tor-browser_en-US

RUN chown -R user:user $HOME \
	&& chmod +x $HOME/tbbw \
  && setcap 'CAP_NET_RAW+eip CAP_NET_ADMIN+eip' $HOME/tbbdnsw

WORKDIR $HOME
USER user
ENTRYPOINT ["dumb-init", "--"]
\end{lstlisting}

Build the docker container and start a worker:

\begin{lstlisting}
docker build -t pulls/worker  .
docker run --privileged -d pulls/worker ./tbbw <IP:port>
\end{lstlisting}

Finally, to extract the data from the resulting torlog-files use the
torlogext and fext tools:

\begin{lstlisting}
torlogext -o results/ data/
fext results
\end{lstlisting}
The torlogext file generates cell-files with the format used by
Wang et al.~\cite{Wang2014a}, and the fext tool extracts features for Wa-kNN.
