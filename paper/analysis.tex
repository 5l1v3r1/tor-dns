\section{Evaluating \name Attacks}
\label{sec:analysis}

\subsection{Attack precision and recall}

To evaluate our \name attacks, we collected traffic traces in May
2016 using Tor Browser~5.5.4.
We modified Tor Browser to not generate network traffic on launch
(\ie, check for
updates, extensions, \etc), and we modified
Tor (bundled with Tor Browser) to log incoming and outgoing cells.
We then performed 100 downloads for each site in the Alexa top
1,000 and one download for each site in the
Alexa top (1k,101k]. We randomly distributed these measurement tasks
to a Docker fleet; each download used a fresh circuit without
guard relay, and a fresh copy of Tor Browser for up to 60 seconds,
in line with the recommendations by Wang and Goldberg~\cite[\S~4]{Wang2013a}.
We cached Tor's network consensus to minimize load on the
network.  We labeled a measurement as successful if we managed to
resolve the domain of the site; we did not prune our dataset further, neglecting
issues like Cloudflare CAPTCHAs, outliers, control cells, and localized
domains~\cite{Juarez2014a}.  Presumably, this means that we will underestimate
the effectiveness of our attack, but we are primarily interested in the
difference between website fingerprinting attacks and \name
attacks~\cite{Wang2013a}.

We perform ten-fold cross-validation for all of our experiments in the open
world setting, monitoring 1,000 sites with 100 instances each, and
100,000 unmonitored sites.
The 1:1 ratio between monitored traces and unmonitored traces is to
ensure that for the classifier there is equal probability in the testing
phase that a trace is a monitored or unmonitored site.
In other words, the \emph{base rate} is 0.5 in our experiments.
Furthermore, for all experiments we specify the starting Alexa rank of the
monitored sites
\emph{when simulating sites visited over the Tor network}.
We always use the same sample data for website fingerprinting.
%When monitoring 1,000 sites starting at rank 1, sites
%[1,1000] are monitored and Alexa [1001,101000] unmonitored. Starting to
%monitor Alexa from rank 100 means that Alexa sites [101,1100] are monitored,
%and Alexa [1,100] and [1101,10100] unmonitored.
%We never monitor an unmonitored site or vice versa.
The popularity of monitored sites
is a key factor in the effectiveness of our attacks.
% note: base rate is per user, while popularity in Alexa for DNS observations
% is world-wide

Figure~\ref{fig:fpt:torpct} shows the recall and precision of our \name
attacks as a function of the percentage of observed Tor exit bandwidth by the
attacker monitoring Alexa sites for sites whose ranks is 10,000 or less.
For recall, both \texttt{ctw} and \texttt{hp} are bound by the
percentage of exit bandwidth observed by the attacker (the percentage is an
upper bound).
It is simply not possible to identify a monitored site in the DNS traffic that
the attacker does not see. At 100\% of exit bandwidth, \texttt{ctw} sees
better recall than \texttt{wf}. For \texttt{hp} the results suggest that:
\begin{equation}
	\label{eq:hprecall}
	\textnormal{recall}_{\texttt{hp}} = \textnormal{recall}_{\texttt{wf}} * \textnormal{pct}.
\end{equation}
This relationship only holds when observing DNS requests gives
a clear advantage to \texttt{hp} in terms of precision over \texttt{wf} (see
the following paragraph).
For precision, the \texttt{hp} attack has an immediate gain over \texttt{wf} as
soon as the attacker can observe {\it any exit bandwidth}.
Although the \texttt{hp} attack has near-perfect precision, the
\texttt{ctw} attack benefits from observing increasingly more exit traffic,
nearly reaching the same levels as \texttt{hp} at 100\% of the exit bandwidth.


\begin{figure}[t]
\centering
\includegraphics[width=0.465\linewidth]{figures/pct-1kx100+100k-recall}
\includegraphics[width=0.465\linewidth]{figures/pct-1kx100+100k-precision}
\caption{Recall and precision for an open-world dataset with monitored sites
at Alexa rank 10k and lower. We compare our \name attacks (\texttt{ctw and
 \texttt{hp}}) to a conventional website fingerprinting attack (\texttt{wf}) for different
 percentages of observed exit bandwidth. }
\label{fig:fpt:torpct}
\end{figure}


Figure~\ref{fig:fpt:alexa} shows recall and precision at 100\% of
observed Tor exit bandwidth as a function of the starting Alexa rank of
monitored sites (we still monitor 1,000 sites).
For popular websites (\ie, websites with a high Alexa ranking),
there is no difference between our attacks and the
\texttt{wf} attack. This is because even with a window of only 60 seconds,
it is almost certain that at least one user visited any of the most popular
sites over Tor. For sites that rank 1,000 or lower (\ie, less popular sites),
both \name attacks show a clear improvement in precision while
\texttt{ctw} also shows improved recall---but only at 100\% observed exit
bandwidth, as shown in Figure~\ref{fig:fpt:torpct}.
These results paint a bleak picture: an attacker that observes the
vast majority of exit bandwidth can use the \texttt{ctw} attack as a perfectly
precise attack with increased recall over a traditional \texttt{wf} attack.
On the other hand, an attacker that can observe a small fraction of exit
bandwidth can use the \texttt{hp} attack as a perfectly precise attack on
relatively {unpopular} sites such as wikileaks.org, which had Alexa rank 10,808
on April 15, 2016.  However, Equation~\ref{eq:hprecall} suggests that
recall will be low.

\begin{figure}[t]
\centering
\includegraphics[width=0.465\linewidth]{figures/alexa-1kx100+100k-recall}
\includegraphics[width=0.465\linewidth]{figures/alexa-1kx100+100k-precision}
\caption{The recall and precision when varying the starting Alexa rank of
monitored sites for 100 percentage of exit bandwidth.}
\label{fig:fpt:alexa}
\end{figure}

\subsection{Sensitivity analysis}

To better understand the extent and limitations of our attacks, we
now study the sensitivity of our \name attacks to website fingerprinting defenses,
TTL clipping, the growth of the Tor network, and website popularity
distribution.  In this section, we assume that an adversary can observe Tor
exit relays representing 33\% of exit bandwidth (as observed on average
by Google) and consider only precision (where we see clear gain from both our
attacks).  Note that the following results largely also apply to weaker
attackers that observe a smaller fraction of exit bandwidth for the \texttt{hp}
attack, but that the \texttt{ctw} attack is more sensitive in terms of precision
to different bandwidth fractions, as shown above.
Unless stated otherwise, we \first perform our evaluation on websites starting
from Alexa rank 10,000 upwards, \second use
2,500 weight-learning rounds, \third have a 60-second window size, \fourth a Tor
network scale of 1.0, and \fifth use the conservative power-law distribution
from Section~\ref{sec:attack:pop}.



\subsubsection{Effect of website fingerprinting defenses}

The Tor Project is working on a website fingerprinting
defense~\cite{adapativepadding}.
Most defenses produce bandwidth and/or latency overhead, with a significant
increase in overhead as the defense becomes stronger.
For example, Juarez \ea
observe an exponential increase in bandwidth overhead as the protection of the
WTF-PAD defense increases~\cite[\S~4.3]{Juarez2016a}.
The goal is to find an optimum that provides strong protection
while keeping the overhead tolerable for Tor users.
To approximate the effect of fingerprinting
defenses on \name attacks, we use Wa-kNN with
random weights and no weight-learning, which significantly reduces the
effectiveness of the attack since some features (like indices of outgoing
packets) are several orders of magnitude more useful
than others~\cite{Juarez2016a}.

\begin{figure}[t]
\centering
\subfigure[Estimating the effect of website fingerprinting defenses.]{
	\includegraphics[width=0.465\linewidth]{figures/rounds-1kx100+100k}
    \label{fig:fpt:var:rounds}
}
\subfigure[Effect of increasing the analysis time window due to TTL clipping.]{
	\includegraphics[width=0.465\linewidth]{figures/window-1kx100+100k}
    \label{fig:fpt:var:window}
}
\subfigure[Effect of Tor network scale for Alexa ranks 10k and 100k.]{
	\includegraphics[width=0.465\linewidth]{figures/scale-1kx100+100k}
    \label{fig:fpt:var:scale}
}
\subfigure[Effect of different website popularity distributions.]{
	\includegraphics[width=0.465\linewidth]{figures/dist-1kx100+100k}
    \label{fig:fpt:var:dist}
}
\caption{The effect on attack precision. The defaults are: Alexa from top 10,000,
2,500 weight-learning rounds,
60-second window size, Tor network scale 1.0, and the conservative
power-law distribution (pc) with $\alpha=1.13$.}
\label{fig:fpt:var}
\end{figure}


Figure~\ref{fig:fpt:var:rounds} shows the effect of weight-learning between 0
and 3,000 rounds.  At few to no rounds, the precision for the
\texttt{wf} attack is below 50\%---a positive classification is more likely to
be wrong than right---while there is a relatively small impact on the
\texttt{hp} and \texttt{ctw} attacks.
For recall, which is not shown in the figure, the bound and relationship is
as in Equation~\ref{eq:hprecall}: for \texttt{wf}, at zero rounds, recall is
0.055; for \texttt{hp} at zero rounds, recall is 0.019. These results suggest
that for website fingerprinting defenses to be effective against \name attacks,
the defense must be tuned to cause low recall even if the parameters of
website fingerprinting attacks are optimized for high recall.

\subsubsection{Effect of Tor's TTL clipping}

\begin{table}[t]
\renewcommand{\tabcaptext}{Median and mean DNS TTL values across Alexa top one million sites. Raw
TTLs are unprocessed, as they appear in DNS lookup traces. Tor TTLs adhere to
Tor's TTL clipping.  Unique refers to the TTLs for unique domains; min unique
only considers the unique domains with the minimum TTL for each
website.}
\topcap{\tabcaptext}
\centering
\begin{tabular}{l r r}
\toprule
\textbf{TTLs} & \textbf{Median TTL (sec)} & \textbf{Mean TTL (sec) $\pm$ Stddev} \\
\midrule
% 2016/04/28 15:52:39 DNS records TTL mean 9780.0, std 42930.5, median 255.0, min 0.0, max 604800.0
Raw & \multirow{ 2}{*}{255} & $9{,}780.0\pm42{,}930.5$ \\ % & 0 & 604800 \\
% 2016/04/28 15:44:05 DNS records TTL mean 701.5, std 755.3, median 255.0, min 60.0, max 1800.0
Tor &  & $701.5\pm\phantom{00{,}}755.3$ \\ %& 60 & 1800 \\
% 2016/04/28 15:52:39 	unique domain TTL mean 13022.2, std 35054.4, median 900.0, min 0.0, max 604800.0
Unique raw & \multirow{ 2}{*}{900} & $13{,}022.2\pm35{,}054.4$ \\ %& 0 & 604800 \\
% 2016/04/28 15:44:05 	unique domain TTL mean 1005.3, std 789.6, median 900.0, min 60.0, max 1800.0
Unique Tor &  & $1{,}005.3\pm\phantom{00{,}}789.6$ \\ %& 60 & 1800 \\
% 2016/04/28 15:52:39 	unique domain _min_ TTL mean 3833.9, std 11073.6, median 60.0, min 0.0, max 604800.0
Min unique raw & \multirow{ 2}{*}{60} & $3{,}833.9\pm11{,}073.6$ \\ % & 0 & 604800 \\
% 2016/04/28 15:44:05 	unique domain _min_ TTL mean 644.2, std 763.8, median 60.0, min 60.0, max 1800.0
Min unique Tor & & $644.2\pm\phantom{00{,}}763.8$ \\ %& 60 & 1800 \\
\bottomrule
\end{tabular}
\bottomcap{\tabcaptext}
\label{tab:ttls}
\end{table}

As discussed in Section~\ref{sec:attack:sim}, due to a bug in Tor, all exit
relays cache DNS responses for 60 seconds, regardless of the DNS response's TTL.
Therefore, a sliding window covering the last 60 seconds of observed DNS
requests suffices to capture all monitored sites through Tor (subject to the
fraction of observed Tor exit bandwidth, and mapping DNS requests to sites).

Table~\ref{tab:ttls} shows the TTL of DNS records in our Alexa top one million
dataset from Section~\ref{sec:dns2site} both for the
TTL as-is (raw) and when clipped (Tor).
We calculate the intended values for TTL clipping, assuming that The Tor Project
will fix the aforementioned bug.
For each of these cases, we
also consider TTLs for all unique domains, and for only the unique
domain for each website with the lowest TTL.  About half of all sites on
Alexa's top one million have a unique domain with a TTL of 60 seconds or
less; 48\% of the raw unique TTLs are below 60 seconds and only 26\%
above 30 minutes. Fixing the Tor clipping bug is therefore not
sufficient; to mitigate \name attacks, the minimum TTL should be
significantly increased.  In this case, we find that Tor's TTL clipping has
no effect on the median TTL, but significantly reduces the mean TTL.

Suppose that Tor eventually fixes the DNS TTL bug, requiring the
attacker to monitor DNS lookups for a time interval equal to the maximum
TTL of all unique domains for any monitored site.
Figure~\ref{fig:fpt:var:window} shows the effect on precision for
different time intervals from 60 seconds to 30 minutes (Tor's {\tt
MAX\_DNS\_ENTRY\_AGE} for keeping entries in an exit's DNS resolver
cache), and for Alexa starting rank 10,000 and 100,000. For \texttt{ctw},
the time interval has a significant effect on both Alexa starting ranks,
while \texttt{hp} is only affected for sites ranked 10,000 or higher;
for less popular sites, the DNS lookup data still significantly improves
fingerprinting precision, even with the larger window size.

\subsubsection{Effect of Tor network growth}
Figure~\ref{fig:fpt:var:scale} scales the size of the Tor network with
respect to site
visits from the estimated status quo to ten times its size, for Alexa starting rank 10,000 and
100,000. At twice its current size, the impact on \name attacks is smaller than
increasing the minimum TTL for DNS caching to three minutes, as shown in
Figure~\ref{fig:fpt:var:window}. These results indicate that \name
attacks will remain
practical for many sites in the Alexa top one million, even as the Tor network grows.
If we overestimated the current Tor network size in the analysis
in Section~\ref{sec:load-freq}, our \name attacks would have even higher
precision, as shown by the data points to the left of the gray line in
Figure~\ref{fig:fpt:var:scale}.

% limitation: webSITES, not wePAGES in our analysis + what we get from DNS.

\subsubsection{Sensitivity to website popularity distribution}

% alexa offsets, all distributions and attacks
To explore the sensitivity of our results to different distributions in
how users visit websites, we now evaluate the effectiveness of \name
attacks with four different website distributions:
\begin{description}
	\item[pc] A conservative power-law distribution
	(with $\alpha=1.13$)
	that we manually fitted to the Alexa top 10,000 data,
	slightly underrepresenting the popularity of top Alexa sites.
	We described this distribution in Section~\ref{sec:attack:pop}.
	\item[pr] A realistic power-law distribution
	(with $\alpha=1.98$)
	that is the best fit according to
	the Python {\tt powerlaw} library by Alstott~\ea~\cite{Alstott2014a} for the Alexa
	top 10,000 data.
	\item[uc] A conservative uniformly random distribution that
	only considers one million active websites browsed over Tor.
	\item[ur] A realistic uniformly random distribution that
          considers 173 million active websites, as reported by Netcraft
          in July 2016 for the Internet~\cite{numberofwebsites}.
\end{description}
Figure~\ref{fig:fpt:var:dist} shows the effect on the precision of the
\texttt{hp} attack for the different distributions as we vary the starting
Alexa rank. The uniform distributions always have nearly perfect precision.
The difference between the two power-law distributions is about one order of
magnitude in terms of starting Alexa rank: the realistic distribution gets
near perfect at 1,000 and the conservative at 10,000.
We conclude that \name attacks are perfectly precise for unpopular sites
because it is unlikely that more than one person is browsing a monitored site
within the timeframe determined by the window length.
