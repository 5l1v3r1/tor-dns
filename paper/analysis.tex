\section{Evaluating \name Attacks}
\label{sec:analysis}

\subsection{Attack precision and recall}

To evaluate our \name attacks, we collected traffic traces in May
2016 using TBB~5.5.4.
We modified TBB so that it does not generate network traffic on launch
(\ie, check for
updates, extensions, etc.), and we modified
Tor (bundled with TBB) to log incoming and outgoing cells.
We then performed 100 downloads for each site in the Alexa top
1k and one download for each site in the
Alexa top (1k,101k]. We randomly distributed these measurement tasks
to a Docker fleet; each download used a fresh circuit without
guards and a fresh copy of TBB for up to 60 seconds,
in line with the recommendations by Wang and Goldberg~\cite{Wang2013a}.
We cached the consensus to avoid causing excessive load on the network.
We considered the measurement to be successful if we managed to resolve
the domain of the site;
we did not prune our dataset further, neglecting issues like CloudFlare
CAPTCHAs, outliers, control cells, and localized domains~\cite{Juarez2014a}.
This likely leads to overall worse results for all attacks than what is
possible, but we are primarily interested in the difference between website
fingerprinting and \name attacks~\cite{Wang2013a}.

We perform ten-fold cross-validation for all of our experiments in the open
world setting, monitoring 1,000 sites with 100 instances each and
100,000 unmonitored sites.
Note the 1:1 ratio between monitored traces and unmonitored traces,
ensuring that for the classifier there is equal probability in the testing
phase that a trace is a monitored or unmonitored site.
In other words, the \emph{base rate} is 0.5 in our experiments.
Furthermore, for all experiments we specify the starting Alexa rank of the
monitored sites
\emph{when simulating sites visited over the Tor network}.
We always use the same sample data for website fingerprinting.
When monitoring 1,000 sites starting at rank 1, sites
[1,1000] are monitored and Alexa [1001,101000] unmonitored. Starting to
monitor Alexa from rank 100 means that Alexa sites [101,1100] are monitored,
and Alexa [1,100] and [1101,10100] unmonitored.
We never monitor an unmonitored site or vice versa.
How popular monitored sites
are is a key factor in the effectiveness of our attacks.
% note: base rate is per user, while popularity in Alexa for DNS observations
% is world-wide

Figure~\ref{fig:fpt:torpct} shows the recall and precision for our \name
attacks as a function of the percentage of observed Tor exit bandwidth by the
attacker monitoring Alexa sites for sites whose ranks are 10,000 or less.
For recall, both \texttt{ctw} and \texttt{hp} are bound by the
percentage of exit bandwidth observed by the attacker (the percentage is an
upper bound).
It is simply not possible to identify a monitored site in the DNS data that
the attacker does not see. At 100\% of exit bandwidth, \texttt{ctw} sees
better recall than \texttt{wf}. For \texttt{hp} the results suggest that:
\begin{equation}
	\label{eq:hprecall}
	\textnormal{recall}_{\texttt{hp}} = \textnormal{recall}_{\texttt{wf}} * \textnormal{pct}
\end{equation}
The above relationship only holds when observing DNS requests gives
a clear advantage to \texttt{hp} in terms of precision over \texttt{wf} (see
following paragraph).
For precision our attacks have an immediate gain over \texttt{wf} as soon as
the attacker can observe {any exit bandwidth}.
Although the \texttt{hp} attack has near-perfect precision, the
\texttt{ctw} attack benefits from observing increasingly more exit traffic,
nearly reaching the same levels as \texttt{hp} at 100\% of the exit bandwidth.


\begin{figure}[t]
\centering
	\includegraphics[width=0.465\linewidth]{figures/fpt/pct/1kx100+100k-recall-ggplot2}
	\includegraphics[width=0.465\linewidth]{figures/fpt/pct/1kx100+100k-precision-ggplot2}
\caption{Recall and precision for an open-world dataset with monitored sites
at Alexa rank 10k and lower. We compare our attacks (\texttt{ctw and
 \texttt{hp}}) to a conventional website fingerprinting attack (\texttt{wf}) for different
 percentages of observed exit bandwidth. }
\label{fig:fpt:torpct}
\end{figure}


Figure~\ref{fig:fpt:alexa} shows recall and precision at 100\% of
observed Tor exit bandwidth as a function of the starting Alexa rank of
monitored sites (we still monitor 1,000 sites).
For high Alexa ranks there is no difference between our attacks and the
\texttt{wf} attack. This is because, even with a window of only 60 seconds,
it is almost certain that at least one user visited any of the most popular
sites over Tor. For sites that rank 1,000 or lower (\ie, less popular),
the \name attacks show a clear improvement in both recall and precision.
These results paint a bleak picture: a small fraction of exit
bandwidth provides a perfectly precise attack on relatively
{unpopular} sites such as \url{wikileaks.org}, which has Alexa rank
10,808.

\begin{figure}[t]
\centering
	\includegraphics[width=0.465\linewidth]{figures/fpt/alexa/1kx100+100k-recall-ggplot2}
	\includegraphics[width=0.465\linewidth]{figures/fpt/alexa/1kx100+100k-precision-ggplot2}
\caption{The recall and precision when varying the starting Alexa rank of
monitored sites for 100 percentage of exit bandwidth.}
\label{fig:fpt:alexa}
\end{figure}

\subsection{Sensitivity analysis}


\if 0
\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{figures/fpt/rounds/1kx100+100k-ggplot2}
\caption{Estimating the effect of website fingerprinting defenses.}
\label{fig:fpt:var:rounds}
\end{figure}

\begin{figure}[t]
\centering
    \includegraphics[width=0.95\linewidth]{figures/fpt/window/1kx100+100k-ggplot2}
\caption{Effect of increasing the analysis time window due to TTL clipping.}
    \label{fig:fpt:var:window}
\end{figure}

\begin{figure}[t]
\centering    \includegraphics[width=0.95\linewidth]{figures/fpt/scale/1kx100+100k-ggplot2}
\caption{Effect of Tor network scale for Alexa ranks 10k and 100k.}
    \label{fig:fpt:var:scale}
\end{figure}


\begin{figure}[t]
\centering    \includegraphics[width=0.95\linewidth]{figures/fpt/dist/1kx100+100k-ggplot2}
\caption{Effect of different website popularity distributions.}   \label{fig:fpt:var:dist}
\end{figure}
\fi


\begin{figure}[t]
\centering
\subfigure[Estimating the effect of website fingerprinting defenses.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/rounds/1kx100+100k-ggplot2}
    \label{fig:fpt:var:rounds}
}
\subfigure[Effect of increasing the analysis time window due to TTL clipping.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/window/1kx100+100k-ggplot2}
    \label{fig:fpt:var:window}
}
\subfigure[Effect of Tor network scale for Alexa ranks 10k and 100k.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/scale/1kx100+100k-ggplot2}
    \label{fig:fpt:var:scale}
}
\subfigure[Effect of different website popularity distributions.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/dist/1kx100+100k-ggplot2}
    \label{fig:fpt:var:dist}
}
\caption{The effect on attack precision. The defaults are: Alexa from top 10,000,
2,500 weight-learning rounds,
60 seconds window size, Tor network scale 1.0, and the conservative
power-law distribution (pc) with $\alpha=1.13$.}
\label{fig:fpt:var}
\end{figure}

To better understand the extent and limitations of our attacks, we
study the sensitivity of our results to website popularity distribution,
website fingerprinting defenses, TTL clipping, and the growth of the Tor
network.  In this section, we assume that an adversary can observe Tor
exit relays representing 33\% of exit bandwith (as observed on average
by Google) and precision (where we see clear gain from both our
attacks).  Unless otherwise stated, we perform our evaluation on
websites starting at Alexa rank 10,000 and proceeding through less
popular websites.



\subsubsection{Effect of website fingerprinting defenses}

Website fingerprinting defenses are being
designed and discussed for deployment in Tor~\cite{adapativepadding}.
The defenses produce bandwidth and/or latency overhead, with a significant
increase in overhead the stronger the defense. For example, Juarez \ea
observe an exponential increase in bandwidth overhead for increasing protection
with WTF-PAD~\cite{DBLP:journals/corr/JuarezIPDW15}.
This leads to the goal of finding an optimal with ``good enough''
protection and minimal overhead.
As a first attempt to approximate the effect of fingerprinting
defenses on \name attacks, we use Wa-kNN with
random weights and no weight-learning: this significantly reduces the
effectiveness of the attack since some features (like indices of outgoing
packers) are several orders of magnitude more useful
than others~\cite{DBLP:journals/corr/JuarezIPDW15}.

Figure~\ref{fig:fpt:var:rounds} shows the effects of between 0 and 3000
rounds of weight-learning. At few to no rounds, the precision for the
\texttt{wf} attack is below 50\%---the classification is more likely to be wrong
than right---while there is no impact on the \texttt{hp} attack and a relatively
small decrease for the \texttt{ctw} attack.
For recall (not shown in the figure), the bound and relationship is
as in Equation~\ref{eq:hprecall}: for \texttt{wf}, at zero rounds, recall is
0.055; for \texttt{hp} at zero rounds, recall is 0.019. These results suggest
that for website fingerprinting defenses to be effective against \name attacks,
the defense must be tuned to provide a low recall even when the parameters of
website fingerprinting attacks are selected for high recall.

\subsubsection{Effect of Tor's TTL clipping}

\begin{table}[t]
\renewcommand{\tabcaptext}{Mean and median DNS TTL values across Alexa top one million sites. Raw
TTLs are unprocessed, as they appear in DNS lookup traces. Tor TTLs adhere to
Tor's TTL clipping.  Unique refers to the TTLs for unique domains; min unique
only considers the unique domains with the minimum TTL for each
website.}
\topcap{\tabcaptext}
\centering
\begin{tabular}{l r r}
\toprule
\textbf{TTLs} & \textbf{Median TTL (sec)} & \textbf{Mean TTL (sec)} \\
\midrule
% 2016/04/28 15:52:39 DNS records TTL mean 9780.0, std 42930.5, median 255.0, min 0.0, max 604800.0
raw & \multirow{ 2}{*}{255} & $9780.0\pm42930.5$ \\ % & 0 & 604800 \\
% 2016/04/28 15:44:05 DNS records TTL mean 701.5, std 755.3, median 255.0, min 60.0, max 1800.0
Tor &  & $701.5\pm\phantom{00}755.3$ \\ %& 60 & 1800 \\
% 2016/04/28 15:52:39 	unique domain TTL mean 13022.2, std 35054.4, median 900.0, min 0.0, max 604800.0
unique raw & \multirow{ 2}{*}{900} & $13022.2\pm35054.4$ \\ %& 0 & 604800 \\
% 2016/04/28 15:44:05 	unique domain TTL mean 1005.3, std 789.6, median 900.0, min 60.0, max 1800.0
unique Tor &  & $1005.3\pm\phantom{00}789.6$ \\ %& 60 & 1800 \\
% 2016/04/28 15:52:39 	unique domain _min_ TTL mean 3833.9, std 11073.6, median 60.0, min 0.0, max 604800.0
min unique raw & \multirow{ 2}{*}{60} & $3833.9\pm11073.6$ \\ % & 0 & 604800 \\
% 2016/04/28 15:44:05 	unique domain _min_ TTL mean 644.2, std 763.8, median 60.0, min 60.0, max 1800.0
min unique Tor & & $644.2\pm\phantom{00}763.8$ \\ %& 60 & 1800 \\
\bottomrule
\end{tabular}
\bottomcap{\tabcaptext}
\label{tab:ttls}
\end{table}

As discussed in Section~\ref{sec:attack:sim}, due to a bug in Tor, the
maximum TTL for DNS responses in any Tor exit relay's DNS resolver cache
is 60 seconds. As a consequence, a sliding window of only the last 60
seconds of all observed DNS requests is enough to capture all visited
monitored sites through Tor (subject to the fraction of observed Tor
exit bandwidth, and mapping DNS requests to sites).

Table~\ref{tab:ttls} shows the TTL of DNS records in our dataset for the
TTL as-is (raw) and when clipped by Tor.  For each of these cases, we
also consider TTLs for all unique domains, and for only the unique
domain for each website with the lowest TTL.  About half of the sites on
Alexa top one million has a unique domain with a TTL of 60 seconds or
shorter; 48\% of the raw unique TTLs are below 60 seconds and only 26\%
above 30 minutes. Fixing the Tor clipping bug is therefore not
sufficient; to mitigate \name attacks, the minimum TTL should be
significantly increased.  We also emulate what the correct TTL values
would be due to TTL clipping supposing that Tor eventually fixes the
aforementioned bug.  In this case, we find that Tor's TTL clipping has
no effect on the median TTL, but significantly reduces the mean TTL.

Suppose that Tor eventually fixes the DNS TTL bug, requiring the
attacker to monitor DNS lookups for a time interval equal to the maximum
TTL of all unique domains for any monitored site.
Figure~\ref{fig:fpt:var:window} shows the effect on precision for
different time intervals from 60 seconds to 30 minutes (Tor's {\tt
  MAX\_DNS\_ENTRY\_AGE} for keeping entries in an exit's DNS resolver
cache) and for Alexa starting rank 10,000 and 100,000. For \texttt{ctw},
the time interval has a significant effect at both Alexa starting ranks,
while \texttt{hp} is only affected for sites ranked 10,000 or higher;
for less popular sites, the DNS lookup data still significantly improves
fingerprinting precision, even with the larger window size.

\subsubsection{Effect of Tor network growth}
Figure~\ref{fig:fpt:var:scale} scales the size of the Tor network with
respect to site
visits from the status quo to ten times its size, for Alexa starting rank 10,000 and
100,000. At twice its current size, the impact on \name attacks is smaller than
increasing the minumum TTL for DNS caching to 180 seconds as shown in
Figure~\ref{fig:fpt:var:window}. These results indicate that \name
attacks will remain
practical for many sites in the Alexa top one million, even as the Tor network grows.

% limitation: webSITES, not wePAGES in our analysis + what we get from DNS.

\subsubsection{Sensitivity to website popularity distribution}

% alexa offsets, all distributions and attacks
To explore the sensitivity of our results to different distributions in
how users visit websites, we now evaluate the effectiveness of \name
attacks with four different website distributions:
\begin{description}
	\item[pc] A conservative power-law distribution
	(with $\alpha=1.13$)
	that we manually fitted to the Alexa top 10,000 data,
	slightly underrepresenting the popularity of top Alexa sites.
	We described this distribution in Section~\ref{sec:attack:pop}.
	\item[pr] A realistic power-law distribution
	(with $\alpha=1.98$)
	that is the best fit according to
	the Python power-law library by Alstott~\ea~\cite{power-law} for the Alexa
	top 10,000 data.
	\item[uc] A conservative uniformly random distribution that
	only considers one million active websites browsed over Tor.
	\item[ur] A realistic uniformly random distribution that
          considers 173 million active websites, as reported by Netcraft
          in July 2016 for the Internet~\cite{numberofwebsites}.
\end{description}
Figure~\ref{fig:fpt:var:dist} shows the effect on the precision of the
\texttt{hp} attack for the different distributions as we vary the starting
Alexa rank. The uniform distributions always have nearly perfect precision.
The difference between the two power-law distributions is about one order of
magnitude in terms of starting Alexa rank: the realistic distribution gets
near perfect at 1,000 and the conservative at 10,000.
We conclude that \name attacks are perfectly precise for unpopular sites
where the probability that someone else than the target browses to a monitored
site within the timeframe given by the window length is negligible.
