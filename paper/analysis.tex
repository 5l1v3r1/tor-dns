\section{Evaluating \name Attacks}
\label{sec:analysis}

\subsection{Attack precision and recall}

To evaluate our \name attacks, we collected traffic traces in May
2016 using Tor Browser~5.5.4.
We modified Tor Browser to not generate network traffic on launch
(\ie, check for
updates, extensions, \etc), and we modified
Tor (bundled with Tor Browser) to log incoming and outgoing cells.
We then performed 100 downloads for each site in the Alexa top
1k and one download for each site in the
Alexa top (1k,101k]. We randomly distributed these measurement tasks
to a Docker fleet; each download used a fresh circuit without
guard relay, and a fresh copy of Tor Browser for up to 60 seconds,
in line with the recommendations by Wang and Goldberg~\cite[\S~4]{Wang2013a}.
We cached Tor's network consensus to avoid causing excessive load on the
network.  We considered the measurement to be successful if we managed to
resolve the domain of the site; we did not prune our dataset further, neglecting
issues like CloudFlare CAPTCHAs, outliers, control cells, and localized
domains~\cite{Juarez2014a}.  Presumably, this means that we will underestimate
the effectiveness of our attack, but we are primarily interested in the
difference between recent website fingerprinting attacks and \name
attacks~\cite{Wang2013a}.

We perform ten-fold cross-validation for all of our experiments in the open
world setting, monitoring 1,000 sites with 100 instances each, and
100,000 unmonitored sites.
Note the 1:1 ratio between monitored traces and unmonitored traces,
ensuring that for the classifier there is equal probability in the testing
phase that a trace is a monitored or unmonitored site.
In other words, the \emph{base rate} is 0.5 in our experiments.
Furthermore, for all experiments we specify the starting Alexa rank of the
monitored sites
\emph{when simulating sites visited over the Tor network}.
We always use the same sample data for website fingerprinting.
When monitoring 1,000 sites starting at rank 1, sites
[1,1000] are monitored and Alexa [1001,101000] unmonitored. Starting to
monitor Alexa from rank 100 means that Alexa sites [101,1100] are monitored,
and Alexa [1,100] and [1101,10100] unmonitored.
We never monitor an unmonitored site or vice versa.
How popular monitored sites
are is a key factor in the effectiveness of our attacks.
% note: base rate is per user, while popularity in Alexa for DNS observations
% is world-wide

Figure~\ref{fig:fpt:torpct} shows the recall and precision for our \name
attacks as a function of the percentage of observed Tor exit bandwidth by the
attacker monitoring Alexa sites for sites whose ranks are 10,000 or less.
For recall, both \texttt{ctw} and \texttt{hp} are bound by the
percentage of exit bandwidth observed by the attacker (the percentage is an
upper bound).
It is simply not possible to identify a monitored site in the DNS data that
the attacker does not see. At 100\% of exit bandwidth, \texttt{ctw} sees
better recall than \texttt{wf}. For \texttt{hp} the results suggest that:
\begin{equation}
	\label{eq:hprecall}
	\textnormal{recall}_{\texttt{hp}} = \textnormal{recall}_{\texttt{wf}} * \textnormal{pct}
\end{equation}
The above relationship only holds when observing DNS requests gives
a clear advantage to \texttt{hp} in terms of precision over \texttt{wf} (see
the following paragraph).
For precision our attacks have an immediate gain over \texttt{wf} as soon as
the attacker can observe {any exit bandwidth}.
Although the \texttt{hp} attack has near-perfect precision, the
\texttt{ctw} attack benefits from observing increasingly more exit traffic,
nearly reaching the same levels as \texttt{hp} at 100\% of the exit bandwidth.


\begin{figure}[t]
\centering
	\includegraphics[width=0.465\linewidth]{figures/fpt/pct/1kx100+100k-recall-ggplot2}
	\includegraphics[width=0.465\linewidth]{figures/fpt/pct/1kx100+100k-precision-ggplot2}
\caption{Recall and precision for an open-world dataset with monitored sites
at Alexa rank 10k and lower. We compare our \name attacks (\texttt{ctw and
 \texttt{hp}}) to a conventional website fingerprinting attack (\texttt{wf}) for different
 percentages of observed exit bandwidth. }
\label{fig:fpt:torpct}
\end{figure}


Figure~\ref{fig:fpt:alexa} shows recall and precision at 100\% of
observed Tor exit bandwidth as a function of the starting Alexa rank of
monitored sites (we still monitor 1,000 sites).
For popular websites (\ie, websites with a high Alexa ranking),
there is no difference between our attacks and the
\texttt{wf} attack. This is because even with a window of only 60 seconds,
it is almost certain that at least one user visited any of the most popular
sites over Tor. For sites that rank 1,000 or lower (\ie, less popular sites),
both \name attacks show a clear improvement in precision while
\texttt{ctw} also shows improved recall---but only at 100\% observed exit
bandwidth, as shown in Figure~\ref{fig:fpt:torpct}.
These results paint a bleak picture: a small fraction of exit
bandwidth provides a perfectly precise attack on relatively
{unpopular} sites such as \url{wikileaks.org}, which had Alexa rank
10,808 at the time of our experiments.

\begin{figure}[t]
\centering
	\includegraphics[width=0.465\linewidth]{figures/fpt/alexa/1kx100+100k-recall-ggplot2}
	\includegraphics[width=0.465\linewidth]{figures/fpt/alexa/1kx100+100k-precision-ggplot2}
\caption{The recall and precision when varying the starting Alexa rank of
monitored sites for 100 percentage of exit bandwidth.}
\label{fig:fpt:alexa}
\end{figure}

\subsection{Sensitivity analysis}


\if 0
\begin{figure}[t]
\centering
\includegraphics[width=0.7\linewidth]{figures/fpt/rounds/1kx100+100k-ggplot2}
\caption{Estimating the effect of website fingerprinting defenses.}
\label{fig:fpt:var:rounds}
\end{figure}

\begin{figure}[t]
\centering
    \includegraphics[width=0.95\linewidth]{figures/fpt/window/1kx100+100k-ggplot2}
\caption{Effect of increasing the analysis time window due to TTL clipping.}
    \label{fig:fpt:var:window}
\end{figure}

\begin{figure}[t]
\centering    \includegraphics[width=0.95\linewidth]{figures/fpt/scale/1kx100+100k-ggplot2}
\caption{Effect of Tor network scale for Alexa ranks 10k and 100k.}
    \label{fig:fpt:var:scale}
\end{figure}


\begin{figure}[t]
\centering    \includegraphics[width=0.95\linewidth]{figures/fpt/dist/1kx100+100k-ggplot2}
\caption{Effect of different website popularity distributions.}   \label{fig:fpt:var:dist}
\end{figure}
\fi


\begin{figure}[t]
\centering
\subfigure[Estimating the effect of website fingerprinting defenses.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/rounds/1kx100+100k-ggplot2}
    \label{fig:fpt:var:rounds}
}
\subfigure[Effect of increasing the analysis time window due to TTL clipping.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/window/1kx100+100k-ggplot2}
    \label{fig:fpt:var:window}
}
\subfigure[Effect of Tor network scale for Alexa ranks 10k and 100k.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/scale/1kx100+100k-ggplot2}
    \label{fig:fpt:var:scale}
}
\subfigure[Effect of different website popularity distributions.]{
	\includegraphics[width=0.465\linewidth]{figures/fpt/dist/1kx100+100k-ggplot2}
    \label{fig:fpt:var:dist}
}
\caption{The effect on attack precision. The defaults are: Alexa from top 10,000,
2,500 weight-learning rounds,
60-second window size, Tor network scale 1.0, and the conservative
power-law distribution (pc) with $\alpha=1.13$.}
\label{fig:fpt:var}
\end{figure}

To better understand the extent and limitations of our attacks, we
study the sensitivity of our results to website fingerprinting defenses,
TTL clipping, the growth of the Tor network, and website popularity
distribution.  In this section, we assume that an adversary can observe Tor
exit relays representing 33\% of exit bandwidth (as observed on average
by Google) and consider only precision (where we see clear gain from both our
attacks).  Unless stated otherwise, we perform our evaluation on
websites starting at Alexa rank 10,000 and proceeding through less
popular websites, use 2,500 weight-learning rounds, have a 60-second window
size, a Tor network scale of 1.0, and use the conservative power-law
distribution from Section~\ref{sec:attack:pop}.



\subsubsection{Effect of website fingerprinting defenses}

Website fingerprinting defenses are being
designed and discussed for deployment in Tor~\cite{adapativepadding}.
The defenses produce bandwidth and/or latency overhead, with a significant
increase in overhead as the defense becomes stronger.
For example, Juarez \ea
observe an exponential increase in bandwidth overhead as the protection of the
defense WTF-PAD~\cite{Juarez2016a} increases.
This leads to the goal of finding an optimum that provides strong protection
while also keeping the overhead tolerable for Tor users.
As a first attempt to approximate the effect of fingerprinting
defenses on \name attacks, we use Wa-kNN with
random weights and no weight-learning: this significantly reduces the
effectiveness of the attack since some features (like indices of outgoing
packets) are several orders of magnitude more useful
than others~\cite{Juarez2016a}.

Figure~\ref{fig:fpt:var:rounds} shows the effects of between 0 and 3,000
rounds of weight-learning. At few to no rounds, the precision for the
\texttt{wf} attack is below 50\%---the classification is more likely to be wrong
than right---while there is no impact on the \texttt{hp} attack and a relatively
small decrease for the \texttt{ctw} attack.
For recall (not shown in the figure), the bound and relationship is
as in Equation~\ref{eq:hprecall}: for \texttt{wf}, at zero rounds, recall is
0.055; for \texttt{hp} at zero rounds, recall is 0.019. These results suggest
that for website fingerprinting defenses to be effective against \name attacks,
the defense must be tuned to provide a low recall even when the parameters of
website fingerprinting attacks are selected for high recall.

\subsubsection{Effect of Tor's TTL clipping}

\begin{table}[t]
\renewcommand{\tabcaptext}{Median and mean DNS TTL values across Alexa top one million sites. Raw
TTLs are unprocessed, as they appear in DNS lookup traces. Tor TTLs adhere to
Tor's TTL clipping.  Unique refers to the TTLs for unique domains; min unique
only considers the unique domains with the minimum TTL for each
website.}
\topcap{\tabcaptext}
\centering
\begin{tabular}{l r r}
\toprule
\textbf{TTLs} & \textbf{Median TTL (sec)} & \textbf{Mean TTL (sec) $\pm$ Stddev} \\
\midrule
% 2016/04/28 15:52:39 DNS records TTL mean 9780.0, std 42930.5, median 255.0, min 0.0, max 604800.0
Raw & \multirow{ 2}{*}{255} & $9{,}780.0\pm42{,}930.5$ \\ % & 0 & 604800 \\
% 2016/04/28 15:44:05 DNS records TTL mean 701.5, std 755.3, median 255.0, min 60.0, max 1800.0
Tor &  & $701.5\pm\phantom{00{,}}755.3$ \\ %& 60 & 1800 \\
% 2016/04/28 15:52:39 	unique domain TTL mean 13022.2, std 35054.4, median 900.0, min 0.0, max 604800.0
Unique raw & \multirow{ 2}{*}{900} & $13{,}022.2\pm35{,}054.4$ \\ %& 0 & 604800 \\
% 2016/04/28 15:44:05 	unique domain TTL mean 1005.3, std 789.6, median 900.0, min 60.0, max 1800.0
Unique Tor &  & $1{,}005.3\pm\phantom{00{,}}789.6$ \\ %& 60 & 1800 \\
% 2016/04/28 15:52:39 	unique domain _min_ TTL mean 3833.9, std 11073.6, median 60.0, min 0.0, max 604800.0
Min unique raw & \multirow{ 2}{*}{60} & $3{,}833.9\pm11{,}073.6$ \\ % & 0 & 604800 \\
% 2016/04/28 15:44:05 	unique domain _min_ TTL mean 644.2, std 763.8, median 60.0, min 60.0, max 1800.0
Min unique Tor & & $644.2\pm\phantom{00{,}}763.8$ \\ %& 60 & 1800 \\
\bottomrule
\end{tabular}
\bottomcap{\tabcaptext}
\label{tab:ttls}
\end{table}

As discussed in Section~\ref{sec:attack:sim}, due to a bug in Tor, all exit
relays cache DNS responses for 60 seconds, regardless of the DNS response's TTL.
Therefore, a sliding window covering the last 60 seconds of all observed DNS
requests suffices to capture all monitored sites through Tor (subject to the
fraction of observed Tor exit bandwidth, and mapping DNS requests to sites).

Table~\ref{tab:ttls} shows the TTL of DNS records in our Alexa top one million
sites dataset from Section~\ref{sec:dns2site} for the
TTL as-is (raw) and when clipped by Tor.  For each of these cases, we
also consider TTLs for all unique domains, and for only the unique
domain for each website with the lowest TTL.  About half of the sites on
Alexa top one million has a unique domain with a TTL of 60 seconds or
shorter; 48\% of the raw unique TTLs are below 60 seconds and only 26\%
above 30 minutes. Fixing the Tor clipping bug is therefore not
sufficient; to mitigate \name attacks, the minimum TTL should be
significantly increased.  We also emulate what the correct TTL values
would be due to TTL clipping supposing that Tor eventually fixes the
aforementioned bug.  In this case, we find that Tor's TTL clipping has
no effect on the median TTL, but significantly reduces the mean TTL.

Suppose that Tor eventually fixes the DNS TTL bug, requiring the
attacker to monitor DNS lookups for a time interval equal to the maximum
TTL of all unique domains for any monitored site.
Figure~\ref{fig:fpt:var:window} shows the effect on precision for
different time intervals from 60 seconds to 30 minutes (Tor's {\tt
  MAX\_DNS\_ENTRY\_AGE} for keeping entries in an exit's DNS resolver
cache), and for Alexa starting rank 10,000 and 100,000. For \texttt{ctw},
the time interval has a significant effect on both Alexa starting ranks,
while \texttt{hp} is only affected for sites ranked 10,000 or higher;
for less popular sites, the DNS lookup data still significantly improves
fingerprinting precision, even with the larger window size.

\subsubsection{Effect of Tor network growth}
Figure~\ref{fig:fpt:var:scale} scales the size of the Tor network with
respect to site
visits from the status quo to ten times its size, for Alexa starting rank 10,000 and
100,000. At twice its current size, the impact on \name attacks is smaller than
increasing the minimum TTL for DNS caching to 180 seconds as shown in
Figure~\ref{fig:fpt:var:window}. These results indicate that \name
attacks will remain
practical for many sites in the Alexa top one million, even as the Tor network grows.

% limitation: webSITES, not wePAGES in our analysis + what we get from DNS.

\subsubsection{Sensitivity to website popularity distribution}

% alexa offsets, all distributions and attacks
To explore the sensitivity of our results to different distributions in
how users visit websites, we now evaluate the effectiveness of \name
attacks with four different website distributions:
\begin{description}
	\item[pc] A conservative power-law distribution
	(with $\alpha=1.13$)
	that we manually fitted to the Alexa top 10,000 data,
	slightly underrepresenting the popularity of top Alexa sites.
	We described this distribution in Section~\ref{sec:attack:pop}.
	\item[pr] A realistic power-law distribution
	(with $\alpha=1.98$)
	that is the best fit according to
	the Python {\tt powerlaw} library by Alstott~\ea~\cite{Alstott2014a} for the Alexa
	top 10,000 data.
	\item[uc] A conservative uniformly random distribution that
	only considers one million active websites browsed over Tor.
	\item[ur] A realistic uniformly random distribution that
          considers 173 million active websites, as reported by Netcraft
          in July 2016 for the Internet~\cite{numberofwebsites}.
\end{description}
Figure~\ref{fig:fpt:var:dist} shows the effect on the precision of the
\texttt{hp} attack for the different distributions as we vary the starting
Alexa rank. The uniform distributions always have nearly perfect precision.
The difference between the two power-law distributions is about one order of
magnitude in terms of starting Alexa rank: the realistic distribution gets
near perfect at 1,000 and the conservative at 10,000.
We conclude that \name attacks are perfectly precise for unpopular sites
where the probability that someone other than the target browses to a monitored
site within the timeframe given by the window length is negligible.
