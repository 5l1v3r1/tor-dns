\section{Analysis}
\label{sec:analysis}

\subsection{WF+DNS attacks}
% flow:
% - we get signal (precision), confirming what kNN says
% - signal depends on pct of exit bandwidth, but improve precision
% 	already at small pct (but big impact on recall)
% - signal depends on monitored sites' popularity

We perform 10-fold cross-validation for all of our experiments in the open
world setting. We monitor 1000 sites with 100 instances each and
$100*1000$ unmonitored sites unless otherwise stated.
\fixme{data collection}
Note the 1:1 ratio between monitored traces and unmonitored traces,
ensuring that for the classifier there is equal probability in the testing
phase that a trace is a monitored or unmonitored site.
In other words, the \emph{base rate} is 0.5 in our experiments.
Furthermore, for all experiments we specify the starting Alexa rank of the
monitored sites. Whem minitoring 1000 sites starting at rank 1, sites
[1,1000] are monitored and Alexa [1001,101000] unmonitored. Starting to monitor
Alexa from rank 100 means that Alexa sites [101,1100] are monitored, and Alexa
 [1,100] and [1101,10100] unmonitored.
We never monitor an unmonitored site or vice versa. How popular monitored sites
are is a key factor in the effectiveness of our attacks.
% note: base rate is per user, while popularity in Alexa for DNS observations
% is world-wide

Figure~\ref{fig:wfdns:torpct} shows the recall and precision for our WF+DNS
attacks as a function of the percentage of observed Tor exit bandwidth by the
attacker monitoring Alexa sites from rank $10^5$.
% TODO: consider moving recall and precision to background
Recall measures the probability that a visit to a monitored page will
be detected, while precision measures the probability that a classification by
the classifier of a visit to a monitored site (positive test outcome) is the
correct one. %Note that precision captures the base rate in an experiment.
For recall both \texttt{ctw} and \texttt{hp} are bound by the
percentage of exit bandwidth observed by the attacker (the percentage is an
upper bound).
Simply put, an attacker cannot identify a monitored site in the DNS data that
she does not see. Note that \texttt{ctw} sees improved recall over \texttt{wf}
at 100\% of exit bandwidth.
For precision our attacks have an imediate gain over \texttt{wf} as soon as
the attacker can observe \emph{any exit bandwidth}.
While the \texttt{hp} attack has constantly near-perfect precision, the
\texttt{ctw} attack benefits from observing more and more of exit bandwidth,
nearly reaching the same levels as \texttt{hp} at 100\%.


\begin{figure}[t]
\centering
\subfigure[Recall]{
	\includegraphics[width=0.466\linewidth]{figures/wfdns/pct/100x100+10000-dns2site-alexa10000-recall}
    \label{fig:wfdns:torpct:recall}
}
\subfigure[Precision]{
	\includegraphics[width=0.466\linewidth]{figures/wfdns/pct/100x100+10000-dns2site-alexa10000-precision}
    \label{fig:wfdns:torpct:precision}
}
\caption{The recall and precision for an open-world dataset, monitoring sites
starting from Alexa rank 10k, comparing our attacks (\texttt{ctw and
 \texttt{hp}}) to a website fingerprinting attack (\texttt{wf}) for different
 percentages of observed exit bandwidth. }
\label{fig:wfdns:torpct}
\end{figure}


Figure~\ref{fig:wfdns:alexa} shows recall and precision at 100 percent of
observed Tor exit bandwidth as a function of the starting Alexa rank of
monitored sites (we still monitor 1000 sites).
For low Alexa ranks there is no difference between our attacks and the
\texttt{wf} attack. This is because, even with a window of only 60 seconds,
it is virtually guaranteed that someone browsed to any of the most popular
sites over Tor. At Alexa rank $10^3$ and onward we se a clear divergence from
the \texttt{wf} attack for both recall and precision:
\texttt{ctw} can improve the recall and precision, while
\texttt{hp} offers almost perfect precision already at Alexa $10^4$.

\begin{figure}[t]
\centering
\subfigure[Recall]{
	\includegraphics[width=0.466\linewidth]{figures/wfdns/alexa/1kx100+100k-offsets-100pct-recall}
    \label{fig:wfdns:alexa:recall}
}
\subfigure[Precision]{
	\includegraphics[width=0.466\linewidth]{figures/wfdns/alexa/1kx100+100k-offsets-100pct-precision}
    \label{fig:wfdns:alexa:precision}
}
\caption{The recall and precision when varying the starting Alexa rank of
monitored sites.}
\label{fig:wfdns:alexa}
\end{figure}

The above results paint a bleak picture: a small fraction of exit
bandwidth provides a perfectly precise attack on relatively
\emph{unpopular} sites such as \url{wikileaks.org} at Alexa rank 10808.
To better understand the implications and limitations of our attacks,
from now on we focus on
33\% of exit bandwith (as observed on average by Google) and
precision (where we see clear gain from our attacks). Unless otherwise stated
we monitor pages starting from Alexa $10^4$.

\begin{figure*}[t]
\centering
\subfigure[Approximating the impact of website fingerprinting defenses.]{
	\includegraphics[width=0.23\linewidth]{figures/wfdns/rounds/10x100+1k-a10k}
    \label{fig:wfdns:var:rounds}
}
\subfigure[Increasing the window size due to TTL clipping at Alexa 10k and 100k.]{
	\includegraphics[width=0.23\linewidth]{figures/wfdns/window/10x100+1k}
    \label{fig:wfdns:var:window}
}
\subfigure[Scaling the Tor network wrt. site visits at Alexa 10k and 100k.]{
	\includegraphics[width=0.23\linewidth]{figures/wfdns/scale/10x100+1k}
    \label{fig:wfdns:var:scale}
}
\subfigure[Distributions \fixme{TODO}]{
	\includegraphics[width=0.23\linewidth]{figures/wfdns/rounds/10x100+1k-a10k}
    \label{fig:wfdns:var:dist}
}
\caption{The impact on the precision of our attacks when observing 33\% of Tor
exit traffic (Google's average). The default weightlearning rounds are 2500,
the window size is 60 seconds, the Tor network scale 1.0, and the distribution
powerlaw with $\alpha=TODO$.}
\label{fig:wfdns:var}
\end{figure*}

\subsubsection{Website fingerprinting defenses}
Website fingerprinting defenses are being
designed and discussed for deployment in Tor.
The defenses produce bandwidth and/or latency overhead with a significant
increase in overhead the stronger the defense\footnote{e.g., Juarez et al.
observe an exponentially growing bandwidth overhead for increasing protection
with WTF-PAD~\cite{DBLP:journals/corr/JuarezIPDW15}.}.
This leads to the goal of finding an optima with ``good enough''
protection and minimal overhead.
As a first attempt to approximate the impact of fingerprinting
defenses on WF+DNS attacks, we use Wa-kNN with
random weights and no weightlearning: this significantly reduces the
effectiveness of the attack since some features (like indices of outgoing
packers) are several orders of magnitude more useful than others.
% rounds [0,3000]
Figure~\ref{fig:wfdns:var:rounds}
\fixme{'What if we got WF defenses deployed?'}
% results, but WF+DNS much stronger than just WF, so implications for defense?

\subsubsection{Tor's TTL clipping}
% plot growing window size? [60, 1800]
% alexa at 10k and 100k
% table with TTLs needed again!
Figure~\ref{fig:wfdns:var:window}
\fixme{'What if we fixed TTL bug + set min TTL to what is now max TTL?'}

\subsubsection{A larger Tor network}
% plot growing tor network? [1, 10]
% problem will not go away by itself
Figure~\ref{fig:wfdns:var:scale}
\fixme{'What if the Tor network got more traffic?'}

\subsubsection{Website popularity distributions}
% alexa offsets, all distributions and attacks
Figure~\ref{fig:wfdns:var:dist}
\fixme{'What if traffic in Tor is more evenly spread among websites?'}



% limitation: webSITES, not wePAGES in our analysis + what we get from DNS.
